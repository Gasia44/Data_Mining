order = "hclust", diag = FALSE)
par(mfrow=c(1,2))
Mat <- home[,-37]
colnames(Mat)<- names(home[,-37])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "square", tl.cex = 0.2, tl.col = 'black',
order = "hclust", diag = FALSE)
par(mfrow=c(1,2))
Mat <- home[,-37]
colnames(Mat)<- names(home[,-37])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "square", tl.cex = 0.3, tl.col = 'black',
order = "hclust", diag = FALSE)
Mat <- away[,-37]
colnames(Mat)<- names(away[,-37])
Correlations <- cor(Mat)
method = "square", tl.cex = 0.7, tl.col = 'black',
corrplot(Correlations, type = "upper", tl.pos = "td",
order = "hclust", diag = FALSE)
Mat <- away[,-37]
colnames(Mat)<- names(away[,-37])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "square", tl.cex = 0.3, tl.col = 'black',
order = "hclust", diag = FALSE)
par(mfrow=c(1,2))
Mat <- home[,-37]
colnames(Mat)<- names(home[,-37])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "square", tl.cex = 0.4, tl.col = 'black',
order = "hclust", diag = FALSE)
Mat <- away[,-37]
colnames(Mat)<- names(away[,-37])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "square", tl.cex = 0.4, tl.col = 'black',
order = "hclust", diag = FALSE)
set.seed(123)
Mat <-train[-72]
colnames(Mat)<- names(train[,-72])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "circle", tl.cex = 0.3, tl.col = 'black',
order = "hclust", diag = FALSE)
par(mfrow=c(1,1))
set.seed(123)
Mat <-train[-72]
colnames(Mat)<- names(train[,-72])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "circle", tl.cex = 0.3, tl.col = 'black',
order = "hclust", diag = FALSE)
par(mfrow=c(1,1))
set.seed(123)
Mat <-train[-72]
colnames(Mat)<- names(train[,-72])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "circle", tl.cex = 0.4, tl.col = 'black',
order = "hclust", diag = FALSE)
par(mfrow=c(1,1))
set.seed(123)
Mat <-train[-72]
colnames(Mat)<- names(train[,-72])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "circle", tl.cex = 0.5, tl.col = 'black',
order = "hclust", diag = FALSE)
####I found how to make it works :D
par(mfrow=c(1,1))
set.seed(123)
Mat <-train[-72]
colnames(Mat)<- names(train[,-72])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "circle", tl.cex = 0.6, tl.col = 'black',
order = "hclust", diag = FALSE)
####I found how to make it works :D
par(mfrow=c(1,1))
set.seed(123)
Mat <-train[-72]
colnames(Mat)<- names(train[,-72])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "square", tl.cex = 0.6, tl.col = 'black',
order = "hclust", diag = FALSE)
home<-train[,c(1,3,4:37,72)]
away<-train[,c(2,3,38:72)]
##Now let's have correlation for each
par(mfrow=c(1,2))
Mat <- home[,-37]
colnames(Mat)<- names(home[,-37])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "square", tl.cex = 0.4, tl.col = 'black',
order = "hclust", diag = FALSE)
Mat <- away[,-37]
colnames(Mat)<- names(away[,-37])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "square", tl.cex = 0.4, tl.col = 'black',
order = "hclust", diag = FALSE)
colnames(Mat)<- names(home[,-37])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "square", tl.cex = 0.5, tl.col = 'black',
order = "hclust", diag = FALSE)
Mat <- away[,-37]
colnames(Mat)<- names(away[,-37])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "square", tl.cex = 0.5, tl.col = 'black',
order = "hclust", diag = FALSE)
par(mfrow=c(1,2))
Mat <- home[,-37]
colnames(Mat)<- names(home[,-37])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "square", tl.cex = 0.5, tl.col = 'black',
order = "hclust", diag = FALSE)
Mat <- away[,-37]
colnames(Mat)<- names(away[,-37])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "square", tl.cex = 0.5, tl.col = 'black',
order = "hclust", diag = FALSE)
CorDataset<-cor(home[1:36], away[1:36])
View(CorDataset)
CorDataset<-cor(home[1:36], away[1:36])
par(mfrow=c(1,2))
hist(home$res)
hist(home$home_reactions)
hist(home$home_reactions)
par(mfrow=c(1,2))
hist(home$home_reactions)
hist(home$home_reactions, tl.cex = 0.5)
hist(home$home_reactions, tl.cex =0.2)
hist(home$home_reactions, tl.cex =1)
hist(home$home_reactions, tl.cex =1.5)
par(mfrow=c(1,2))
hist(home$home_reactions, tl.cex =1.5)
hist(home$home_team_points)
qplot(home$home_curve)
library(ggplot2)
qplot(home$home_curve)
library(ggplot2)
par(mfrow=c(1,2))
hist(home$home_reactions, tl.cex =1.5)
hist(home$home_team_points)
qplot(home$home_curve)
hist(home$home_reactions, tl.cex =1.5)
hist(home$home_reactions, tl.cex =1.5)
par(mfrow=c(1,2))
hist(home$home_reactions, tl.cex =1.5)
par(mfrow=c(1,1))
hist(home$home_reactions, tl.cex =1.5)
hist(home_team_points, data=home, geom="histogram")
hist(home_reactions, data=home, geom="histogram")
hist(home$home_reactions, geom="histogram")
hist(home$home_reactions, geom="histogram")
par(mar=c(1,1,1,1))
hist(home$home_reactions, geom="histogram")
qplot(home$home_curve, )
par(mar=c(0.7,1,1,1))
hist(home$home_reactions, geom="histogram")
qplot(home$home_curve, )
par(mar=c(0.7,0.7,0.7,0.7))
hist(home$home_reactions, geom="histogram")
qplot(home$home_curve, )
par(mfrow=c(1,2))
hist(home$home_reactions, tl.cex =1.5)
par(mar=c(0.5,0.5,0.5,0.5))
hist(home$home_reactions, tl.cex =1.5)
dev.off()
library(ggplot2)
par(mfrow=c(1,2))
hist(home$home_reactions, tl.cex =1.5)
hist(home$home_reactions, tl.cex =1.5)
hist(away$home_reactions, tl.cex =1.5)
hist(away$away_reactions, tl.cex =1.5)
library(ggplot2)
par(mfrow=c(1,2))
hist(home$home_reactions, tl.cex =1.5)
hist(away$away_reactions, tl.cex =1.5)
hist(home$home_reactions, tl.cex =1.5, xlab="Reaction")
hist(home$home_reactions, tl.cex =1.5, xlab="Reaction")
hist(home$home_reactions, xlab="Reaction")
hist(home$home_reactions, xlab="Reaction", main="Home")
hist(away$away_reactions, ,xlab="Reaction", main="away")
par(mfrow=c(1,2))
hist(home$home_reactions, xlab="Reaction", main="Home")
hist(away$away_reactions, ,xlab="Reaction", main="away")
par(mfrow=c(1,2))
hist(home$home_reactions, xlab="Reaction", main="Home")
hist(away$away_reactions, ,xlab="Reaction", main="away")
hist(away$away_reactions,xlab="Reaction", main="away")
hist(train$away_reactions,xlab="Reaction", main="away")
par(mfrow=c(1,2))
hist(train$home_reactions, xlab="Reaction", main="Home")
hist(train$away_reactions,xlab="Reaction", main="Away")
fit<-rpart(result1~., data=train, method="class", minsplit=20, minbucket=5, cp=0.01)
library(rpart)
library(rpart.plot)
library(rattle)
fit<-rpart(result1~., data=train, method="class", minsplit=20, minbucket=5, cp=0.01)
pred_class<-predict(fit, test, type="class")
confusionMatrix(pred_class, test_Student$gender)
library(caret)
library(caret)
e
confusionMatrix(pred_class, test_Student$gender)
confusionMatrix(pred_class, test$result1)
confusionMatrix(pred_class, test$result1, positive = "HW")
chisq.test(train$result1, train$home_team_points)
chisq.test(table(train$result1, train$home_team_points))
a<-chisq.test(table(train$result1, train$home_team_points))
a
library(randomForest)
set.seed(2016)
model<-randomForest(result1~., data=train, ntree=500)
home[,x]<- (home[,x]== away[,x]) 1:0
for(x in 1:36){
home[,x]<- (home[,x]> away[,x]) 1:0
for(x in 1:36){
for(y in 1:nrow(home))
if(home[y,x]> away[y,x])
{
home[y,x]<-1
} else{
home[y,x]<-0
}
}
View(home)
library(AUCRF)
train$result1<-factor(train$result1, levels=c("HW","HDW"), labels=c(1,0))
fm<-formula(result1~.)
set.seed(2016)
fit<- AUCRF(fm, data=train, ntree=100, nodesize=20)
summary(fit)
plot(fit, which=c("auc","ranking","psel"), showOpt=TRUE, digits=4,
maxvars=NULL)
plot(fit, which=c("auc","ranking","psel"), showOpt=TRUE, digits=4, maxvars=NULL)
plot(fit,  showOpt=TRUE, digits=4, maxvars=NULL)
plot(fit,  showOpt=TRUE, digits=4, maxvars=NULL)
plot(fit,  showOpt=TRUE, digits=4, maxvars=NULL)
plot(fit, which=c("auc","ranking","psel"), showOpt=TRUE, digits=4, maxvars=NULL)
plot(fit, showOpt=TRUE, digits=4, maxvars=NULL)
plot(fit, showOpt=TRUE, digits=4, maxvars=NULL)
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
set.seed(2016)
metric <- "Accuracy"
tunegrid <- expand.grid(.mtry=c(8:15))
rf_gridsearch <- train(result1~., data=train, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)
set.seed(2016)
modelOne<-randomForest(result1~., data=home, ntree=500)
prOne<-predict(modelOne, newdata =test)
confusionMatrix(prOne, test$result1, positive="HW")
load("Soccer.rda")
library(ggplot2)
library(lattice)
library(caret)
set.seed(2016)
TrainIndex<-createDataPartition(soccer$result1, p=0.8, list=FALSE)
test<-soccer[-TrainIndex,]
train<-soccer[TrainIndex,]
# Question 1. Do some descriptive analytics (charts, tests, etc)
# to find interesting patterns in the data (10 points)
###First analyse is that all the variables are numeric except the result1
###Second analyse is that each row represents a game and the skills of two teams: home team, and away team
library(corrplot)
par(mar=c(100,100,0,0))
###Let's do correlation analyses:
####I found how to make it works :D
par(mfrow=c(1,1))
set.seed(123)
Mat <-train[-72]
colnames(Mat)<- names(train[,-72])
Correlations <- cor(Mat)
corrplot(Correlations, type = "upper", tl.pos = "td",
method = "square", tl.cex = 0.6, tl.col = 'black',
order = "hclust", diag = FALSE)
##Just by visual we can see that we have a variables that are correlated
#(Dark Blues means high correlations)
##PS when i say home variables, i mean the variables that start with
#Home word, the same for away
##With analyzing the plot, we can see that home variables are
#highly correlated with each other, and away variables are highly
#correlated with each other
#However home and away variables are not very much correlated
#By looking to our variables we can see that we have team... and away...
#This intuitively makes us want to seperate the data
##So let's seperate the home from away:
home<-train[,c(1,3,4:37,72)]
away<-train[,c(2,3,38:72)]
new<-0
new[y,x]<-home[y,x]-away[y,x]
for(x in 1:36){
for(y in 1:nrow(home))
{
new[y,x]<-home[y,x]-away[y,x]
}
}
for(x in 1:36){
for(y in 1:nrow(home))
{
home[y,x]<-home[y,x]-away[y,x]
}
}
set.seed(2016)
modelOne<-randomForest(result1~., data=home, ntree=500)
prOne<-predict(modelOne, newdata =test)
confusionMatrix(prOne, test$result1, positive="HW")
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
set.seed(2016)
metric <- "Accuracy"
tunegrid <- expand.grid(.mtry=c(10:13))
rf_gridsearch <- train(result1~., data=train, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)
View(home)
home<-train[,c(1,3,4:37,72)]
#Let me try to keep only the absolute difference between them:
for(x in 1:36){
for(y in 1:nrow(home))
{
home[y,x]<-abs(home[y,x]-away[y,x])
}
}
set.seed(2016)
modelTwo<-randomForest(result1~., data=home, ntree=500)
prOne<-predict(modelTwo, newdata =test)
confusionMatrix(prOne, test$result1, positive="HW")
prTwo<-predict(modelTwo, newdata =test)
confusionMatrix(prTo, test$result1, positive="HW")
confusionMatrix(prTwo, test$result1, positive="HW")
prTwo<-predict(modelTwo, newdata =test)
confusionMatrix(prTwo, test$result1, positive="HW")
home<-train[,c(1,3,4:37,72)]
c(home, away, x.same = NA, y.same = NA,
layout = NULL, merge.legends = FALSE, recursive = FALSE)
xyplot.list(x, data = NULL, ..., FUN = xyplot,
y.same = TRUE, x.same = NA, layout = NULL,
merge.legends = FALSE)
x<-c(home, away, x.same = NA, y.same = NA,
layout = NULL, merge.legends = FALSE, recursive = FALSE)
xyplot.list(x, data = NULL, ..., FUN = xyplot,
y.same = TRUE, x.same = NA, layout = NULL,
merge.legends = FALSE)
x<-c(home, away, home.same = NA, away.same = NA,
layout = NULL, merge.legends = FALSE, recursive = FALSE)
xyplot.list(x, data = NULL, ..., FUN = xyplot,
y.same = TRUE, x.same = NA, layout = NULL,
merge.legends = FALSE)
x
xyplot.list(x, data = NULL, FUN = xyplot,
y.same = TRUE, x.same = NA, layout = NULL,
merge.legends = FALSE)
home<-train[,c(1,3,4:37,72)]
for(x in 1:36){
for(y in 1:nrow(home))
{
home[y,x]<-home[y,x]+away[y,x]
}
}
View(home)
set.seed(2016)
modelTwo<-randomForest(result1~., data=home, ntree=500)
prTwo<-predict(modelTwo, newdata =test)
confusionMatrix(prTwo, test$result1, positive="HW")
View(home)
View(away)
View(home)
View(home)
View(away)
View(home)
View(away)
View(away)
for(x in 1:36){
for(y in 1:nrow(home))
{
home[y,x]<-(home[y,x]+away[y,x])/2
}
}
set.seed(2016)
modelTwo<-randomForest(result1~., data=home, ntree=500)
prTwo<-predict(modelTwo, newdata =test)
confusionMatrix(prTwo, test$result1, positive="HW")
?AUCRF
library(AUCRF)
train$result1<-factor(train$result1, levels=c("HW","HDW"), labels=c(1,0))
fm<-formula(result1~.)
set.seed(2016)
fit<- AUCRF(fm, data=train, ntree=100, nodesize=20)
summary(fit)
OptimalSet(fit)
fit$`OOB-AUCopt`
plot(fit, showOpt=TRUE, digits=4, maxvars=NULL)
set.seed(2016)
set.seed(2016)
set.seed(2016)
prAUCRF<-predict(fit, newdata =test)
fit<- AUCRF(fm, data=train, ntree=100, nodesize=20, predict=T)
fm<-formula(result1~.)
set.seed(2016)
fit<- AUCRF(fm, data=train, ntree=100, nodesize=20, predict=T)
fm
fit<- AUCRF(result1~., data=train, ntree=100, nodesize=20, predict=T)
set.seed(2016)
fit<- AUCRF(result1~., data=train, ntree=100, nodesize=20, predict=T)
summary(fit)
fit$call
fit$data
fit$ranking
fit$Xopt
fit$`OOB-AUCopt`
fit$Kopt
OptimalSet(fit)
fit$ImpMeasure
load("Soccer.rda")
load("Soccer.rda")
library(ggplot2)
library(lattice)
library(caret)
set.seed(2016)
TrainIndex<-createDataPartition(soccer$result1, p=0.8, list=FALSE)
train<-soccer[TrainIndex,]
test<-soccer[-TrainIndex,]
library(AUCRF)
library(AUCRF)
train$result1<-factor(train$result1, levels=c("HW","HDW"), labels=c(1,0))
test$result1<-factor(test$result1, levels=c("HW","HDW"), labels=c(1,0))
set.seed(2016)
fit<- AUCRF(result1~., data=train, ntree=100, nodesize=20)
summary(fit)
fit$`OOB-AUCopt`
OptimalSet(fit)
fit$RFopt
#`OOB-AUCopt` 0.6950215
aa<-AUCRFcv(fir, nCV = 5, M = 20)
aa<-AUCRFcv(fit, nCV = 5, M = 20)
fitCV<-AUCRFcv(fit, nCV = 5, M = 20)
plot(fit, showOpt=TRUE, digits=4, maxvars=NULL)
plot(fitCV)
for(x in 1:36){
for(y in 1:nrow(home))
if(home[y,x]> away[y,x])
{
home[y,x]<-1
} else{
home[y,x]<-0
}
}
home<-train[,c(1,3,4:37,72)]
away<-train[,c(2,3,38:72)]
for(x in 1:36){
for(y in 1:nrow(home))
if(home[y,x]> away[y,x])
{
home[y,x]<-1
} else{
home[y,x]<-0
}
}
a<-chisq.test(table(h$result1, train$home_team_points))
a<-chisq.test(table(h$result1, train$home_team_points))
a<-chisq.test(table(train$result1, train$home_team_points))
a
a<-chisq.test(table(train$result1, train$away_team_points))
a
a<-chisq.test(table(train$result1, train$home_team_points))
a
a<-chisq.test(table(train$result1, train$away_team_points))
a
home<-train[,c(1,3,4:37,72)]
away<-train[,c(2,3,38:72)]
for(x in 1:36){
for(y in 1:nrow(home))
if(home[y,x]> away[y,x])
{
home[y,x]<-1
} else{
home[y,x]<-0
}
}
set.seed(2016)
bestmtry <- tuneRF(home[,-37], home$result1, stepFactor=0.7, improve=0.01, ntree=500)
set.seed(2016)
modelOne<-randomForest(result1~., mtry=1, data=home, ntree=500)
set.seed(2016)
prOne<-predict(modelOne, newdata =test)
confusionMatrix(prOne, test$result1, positive="HW")
confusionMatrix(prOne, test$result1, positive="1")
home<-train[,c(1,3,4:37,72)]
away<-train[,c(2,3,38:72)]
for(x in 1:36){
for(y in 1:nrow(home))
{
home[y,x]<-home[y,x]-away[y,x]
}
}
set.seed(2016)
set.seed(2016)
bestmtry <- tuneRF(home[,-37], home$result1, stepFactor=0.7, improve=0.01, ntree=500)
set.seed(2016)
modelOne<-randomForest(result1~., mtry= , data=home, ntree=500)
modelOne<-randomForest(result1~., mtry=4 , data=home, ntree=500)
set.seed(2016)
modelOne<-randomForest(result1~., mtry=4 , data=home, ntree=500)
prOne<-predict(modelOne, newdata =test)
confusionMatrix(prOne, test$result1, positive="HW")
confusionMatrix(prOne, test$result1, positive="1")
