trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.002,1,0.002)))
ff$results
ff$bestTune
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
ff <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.002,0.1,0.002)))
ff$results
ff$bestTune
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
ff <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.002,0.2,0.002)))
ff$results
ff$bestTune
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
ff <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.001,0.2,0.001)))
fit1<-rpart(Class~., data=v_train, method="class", minsplit=6, minbucket=2, cp=0.1)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
library(rattle)
asRules(fit)
library(rattle)
asRules(fit1)
asRules(fit)
fit1<-rpart(Class~., data=v_train, method="class", minsplit=6, minbucket=2, cp=0.01)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=6, minbucket=2, cp=0.02)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=6, minbucket=2, cp=0.2)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=6, minbucket=2, cp=0.01)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
ff <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.001,0.2,0.001)))
ff$bestTune
fit2<-rpart(Class~., data=v_train, method="class", cp=0.008)
pred_class2<-predict(fit2, v_test, type="class")
confusionMatrix(pred_class2, v_test$Class, positive="republican")
View(v_test)
fit1<-rpart(Class~., data=v_train, method="class", minsplit=6, minbucket=2, cp=0.01)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=7, minbucket=2, cp=0.01)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=9, minbucket=3, cp=0.01)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=12, minbucket=4, cp=0.01)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=6, minbucket=2, cp=0.01)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
library(rattle)
asRules(fit1)
pred_prob<-predict(fit1,v_test, type="prob")
pred<-prediction(pred_prob[,2],v_test$Class)
perf<-performance(pred,"tpr","fpr")
performance(pred,"auc")@y.values
#the area under the curve: 0.8160173
plot(perf)
pred_prob<-predict(fit1,v_test, type="prob")
pred<-prediction(pred_prob[,2],v_test$Class)
perf<-performance(pred,"tpr","fpr")
performance(pred,"auc")@y.values
#the area under the curve: 0.8427128
plot(perf)
fit1<-rpart(Class~., data=v_train, method="class", minsplit=6, minbucket=2, cp=0.0001)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
library(rattle)
asRules(fit1)
fit1<-rpart(Class~., data=v_train, method="class", minsplit=6, minbucket=2, cp=0.001)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=6, minbucket=2, cp=0.001)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
library(rattle)
asRules(fit1)
pred_prob<-predict(fit1,v_test, type="prob")
pred<-prediction(pred_prob[,2],v_test$Class)
perf<-performance(pred,"tpr","fpr")
performance(pred,"auc")@y.values
#the area under the curve: 0.8427128
plot(perf)
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
ff <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0001,0.01,0.001)))
ff$results
ff$bestTune
fit2<-rpart(Class~., data=v_train, method="class", cp=0.0091)
pred_class2<-predict(fit2, v_test, type="class")
confusionMatrix(pred_class2, v_test$Class, positive="republican")
prp(fit2, type=1, extra=4, faclen=0,tweak=1.0, main="Decision Tree for voting")
fit
fancyRpartPlot(fit2, tweak=1.)
names(v_test)
load("voting_test.rda")
load("voting_train.rda")
?make.names
names(v_test)
names(v_test)<-make.names(names(v_test) , unique = TRUE)
names(v_test)
names(v_train)<-make.names(names(v_train) , unique = TRUE)
names(v_train)
#2. Create a decision tree with the library rpart on the
# training set. Use the variable Class as dependent
#variable and all other variables as independent. (6.25)
library(rpart)
fit<-rpart(Class~., data=v_train, method="class")
load("voting_test.rda")
load("voting_train.rda")
load("voting_test.rda")
load("voting_train.rda")
?make.names
names(v_test)
names(v_test)<-make.names(names(v_test) , unique = TRUE)
names(v_test)
names(v_train)<-make.names(names(v_train) , unique = TRUE)
names(v_train)
#2. Create a decision tree with the library rpart on the
# training set. Use the variable Class as dependent
#variable and all other variables as independent. (6.25)
library(rpart)
fit<-rpart(Class~., data=v_train, method="class")
library(rpart.plot)
library(rattle)
prp(fit, type=1, extra=4, faclen=0,tweak=1.0, main="Decision Tree for voting")
prp(fit, type=1, extra=4, faclen=0,tweak=1.1, main="Decision Tree for voting")
fit
fancyRpartPlot(fit, tweak=1.)
prp(fit, type=1, extra=4, faclen=0,tweak=1.1, main="Decision Tree for voting")
prp(fit, type=1, extra=4, faclen=0,tweak=1.5, main="Decision Tree for voting")
prp(fit, type=1, extra=4, faclen=0,tweak=1.05, main="Decision Tree for voting")
prp(fit, type=1, extra=4, faclen=0,tweak=1., main="Decision Tree for voting")
fancyRpartPlot(fit, tweak=1.)
library(ggplot2)
library(lattice)
library(caret)
pred_class<-predict(fit, v_test,type="class")
pred_class<-predict(fit, v_test, type="class")
pred_class<-predict(fit, v_test,type="class")
table(Actual=v_test$Class, Prediction=pred_class1)
confusionMatrix(pred_class, v_test$Class, positive="republican")
pred_class<-predict(fit, v_test,type="class")
pred_class<-predict(fit, v_test, type="class")
table(Actual=v_test$Class, Prediction=pred_class1)
table(Actual=v_test$Class, Prediction=pred_class)
table( Prediction=pred_class,Actual=v_test$Class,
table( Prediction=pred_class,Actual=v_test$Class)
pred_class<-predict(fit, v_test,type="class")
pred_class<-predict(fit, v_test,type="class")
table( Prediction=pred_class,Actual=v_test$Class)
confusionMatrix(pred_class, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=9, minbucket=6, cp=0.01)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=6, minbucket=2, cp=0.001)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=15, minbucket=4, cp=0.001)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=2, minbucket=1, cp=0.001)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=5, minbucket=1, cp=0.01)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=5, minbucket=1, cp=0.02)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=6, minbucket=2, cp=0.003)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=5, minbucket=1, cp=0.01)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=5, minbucket=4, cp=0.01)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=6, minbucket=2, cp=0.001)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=7, minbucket=4, cp=0.01)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
fit1<-rpart(Class~., data=v_train, method="class", minsplit=6, minbucket=2, cp=0.001)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
library(rattle)
asRules(fit1)
asRules(fit)
pred_prob<-predict(fit1,v_test, type="prob")
pred<-prediction(pred_prob[,2],v_test$Class)
perf<-performance(pred,"tpr","fpr")
performance(pred,"auc")@y.values
#the area under the curve: 0.8632756
plot(perf)
View(pred_prob)
printcp(fit)
min.xerror <- fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"]
min.xerror
printcp(fit)
min.xerror <- fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"]
min.xerror
library(caret)
library(pROC)
ctrl = trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
set.seed(2016)
f = train(Class ~ ., data = v_train, trControl = ctrl, method = "rpart", metric='ROC')
#plot(f)
f$bestTune
f$results
ctrl = trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
set.seed(2016)
f = train(Class ~ ., data = v_train, trControl = ctrl, method = "rpart", metric='ROC')
#plot(f)
f$bestTune
f$results
fit2<-rpart(Class~., data=v_train, method="class", cp=.01984127)
pred_class2<-predict(fit2, v_test, type="class")
confusionMatrix(pred_class2, v_test$Class, positive="republican")
set.seed(1995)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(4444)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(4444)
ff <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0001,0.01,0.001)))
ff$results
ff$bestTune
fit2<-rpart(Class~., data=v_train, method="class", cp=0.0041)
pred_class2<-predict(fit2, v_test, type="class")
confusionMatrix(pred_class2, v_test$Class, positive="republican")
ff$results
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0001,0.01,0.0001)))
ff$results
ff <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0001,0.01,0.0001)))
ff$results
ff$bestTune
fit2<-rpart(Class~., data=v_train, method="class", cp=0.0087)
pred_class2<-predict(fit2, v_test, type="class")
confusionMatrix(pred_class2, v_test$Class, positive="republican")
prp(fit2, type=1, extra=4, faclen=0,tweak=1.0, main="Decision Tree for voting")
fit
fancyRpartPlot(fit2, tweak=1.)
names(v_test)
set.seed(2015)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2015)
ff <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0001,0.01,0.0001)))
ff$results
ff$bestTune
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
ff <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0001,0.01,0.0001)))
ff$results
ff$bestTune
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
ff <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0001,0.1,0.0001)))
ff$results
ff$bestTune
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
ff <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0001,0.1,0.0001)))
fit2<-rpart(Class~., data=v_train, method="class", cp=0.0087)
pred_class2<-predict(fit2, v_test, type="class")
confusionMatrix(pred_class2, v_test$Class, positive="republican")
prp(fit2, type=1, extra=4, faclen=0,tweak=1.0, main="Decision Tree for voting")
fancyRpartPlot(fit2, tweak=1.)
prp(fit2, type=1, extra=4, faclen=0,tweak=1.0, main="Decision Tree for voting")
prp(fit, type=1, extra=4, faclen=0,tweak=1., main="Decision Tree for voting")
fancyRpartPlot(fit, tweak=1.)
fancyRpartPlot(fit2, tweak=1.)
prp(fit2, type=1, extra=4, faclen=0,tweak=1.0, main="Decision Tree for voting")
printcp(fit)
min.xerror <- fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"]
min.xerror
ff$results
printcp(fit)
min.xerror <- fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"]
min.xerror
prp(fit2, type=1, extra=4, faclen=0,tweak=1.0, main="Decision Tree for voting")
fancyRpartPlot(fit2, tweak=1.)
names(v_test)
ff$results
fit2<-rpart(Class~., data=v_train, method="class", cp=0.0131)
pred_class2<-predict(fit2, v_test, type="class")
confusionMatrix(pred_class2, v_test$Class, positive="republican")
ff$results
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
ff <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0001,0.01,0.0001)))
ff$bestTune
ff$results
ff <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.002,0.1,0.002)))
ff$bestTune
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
ff <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.002,0.1,0.002)))
ff$bestTune
ff$bestTune
ff$results
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
ff <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0002,0.1,0.0002)))
ff$bestTune
ff$results
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
ff <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0001,0.1,0.0001)))
ff$results
ff$bestTune
ctrl = trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
set.seed(2016)
f = train(Class ~ ., data = v_train, trControl = ctrl, method = "rpart", metric='ROC')
#plot(f)
f$bestTune
f$results
fit2<-rpart(Class~., data=v_train, method="class", cp=.01984127)
pred_class2<-predict(fit2, v_test, type="class")
confusionMatrix(pred_class2, v_test$Class, positive="republican")
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
try <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0001,0.1,0.0001)))
prp(fit2, type=1, extra=4, faclen=0,tweak=1.0, main="Decision Tree for voting")
try$bestTune
#I got that best cp=0.0131
#Let me see on the Decision Tree
fit2<-rpart(Class~., data=v_train, method="class", cp=0.0131)
pred_class2<-predict(fit2, v_test, type="class")
confusionMatrix(pred_class2, v_test$Class, positive="republican")
fit2<-rpart(Class~., data=v_train, method="class", cp=0.0131)
pred_class2<-predict(fit2, v_test, type="class")
confusionMatrix(pred_class2, v_test$Class, positive="republican")
printcp(fit)
min.xerror <- fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"]
min.xerror
try$results
prp(fit2, type=1, extra=4, faclen=0,tweak=1.0, main="Decision Tree for voting")
prp(fit2, type=1, extra=4, faclen=0,tweak=1.0, main="Decision Tree for voting")
fancyRpartPlot(fit2, tweak=1.)
names(v_test)
library(pROC)
ctrl = trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)
set.seed(2016)
f = train(Class ~ ., data = v_train, trControl = ctrl, method = "rpart", metric='ROC')
f$bestTune
f$results
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
try <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0001,0.1,0.0001)))
try$bestTune
try$bestTune
try$results
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
try <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0001,0.1,0.0002)))
try$bestTune
try$results
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
try <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0001,0.1,0.0001)))
pred_prob<-predict(fit1,v_test, type="prob")
pred<-prediction(pred_prob[,2],v_test$Class)
perf<-performance(pred,"tpr","fpr")
performance(pred,"auc")@y.values
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
try <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0001,0.1,0.0001)))
try$bestTune
try$results
prp(fit2, type=1, extra=4, faclen=0,tweak=1.0, main="Decision Tree for voting")
fancyRpartPlot(fit2, tweak=1.)
load("voting_test.rda")
load("voting_train.rda")
?make.names
names(v_test)
names(v_test)<-make.names(names(v_test) , unique = TRUE)
names(v_test)
names(v_train)
names(v_test)
names(v_train)<-make.names(names(v_train) , unique = TRUE)
names(v_train)
#2. Create a decision tree with the library rpart on the
# training set. Use the variable Class as dependent
#variable and all other variables as independent. (6.25)
library(rpart)
fit<-rpart(Class~., data=v_train, method="class")
#fit<-rpart(Class~handicapped.infants+water.project.cost.sharing+adoption.of.the.budget.resolution+
#          +el.salvador.aid+religious.groups.in.schools+anti.satellite.test.ban+
#           +aid.to.nicaraguan.contras+mx.missile+immigration+synfuels.corporation.cutback+
#           +education.spending+superfund.right.to.sue+crime+duty.free.exports+export.administration.act.south.africa, data=v_train, method="class")
fit<-rpart(Class~., data=v_train, method="class")
#3. Plot the decision tree with the library prp and
# rattle. Make sure you are getting clear and legible
# plot without overlapping nodes. (6.25)
library(rpart.plot)
library(rattle)
prp(fit, type=1, extra=4, faclen=0,tweak=1., main="Decision Tree for voting")
fancyRpartPlot(fit, tweak=1.)
names(v_test)
#4. Make prediction on the testing set. Report the accuracy
# of your model. Take republican as a positive class. (6.25)
library(ggplot2)
library(lattice)
library(caret)
pred_class<-predict(fit, v_test,type="class")
table( Prediction=pred_class,Actual=v_test$Class)
confusionMatrix(pred_class, v_test$Class, positive="republican")
#Accuracy=0.8056
#5. Now start playing with differnet parameters of your
# tree (cp, minbucket, minsplit). Your goal is to get a
# better model than the first one, i.e. the accuracy
# of your model should be higher than the initial one. (6.25)
fit1<-rpart(Class~., data=v_train, method="class", minsplit=9, minbucket=6, cp=0.01)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
# Accuracy : 0.8056
fit1<-rpart(Class~., data=v_train, method="class", minsplit=15, minbucket=4, cp=0.001)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
#Accuracy : 0.7963
fit1<-rpart(Class~., data=v_train, method="class", minsplit=5, minbucket=4, cp=0.01)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
#Accuracy :  0.8056
fit1<-rpart(Class~., data=v_train, method="class", minsplit=6, minbucket=2, cp=0.001)
pred_class1<-predict(fit1, v_test, type="class")
confusionMatrix(pred_class1, v_test$Class, positive="republican")
library(rattle)
asRules(fit)
pred_prob<-predict(fit1,v_test, type="prob")
pred<-prediction(pred_prob[,2],v_test$Class)
perf<-performance(pred,"tpr","fpr")
performance(pred,"auc")@y.values
#the area under the curve: 0.8632756
plot(perf)
pred_prob<-predict(fit1,v_test, type="prob")
pred<-prediction(pred_prob[,2],v_test$Class)
perf<-performance(pred,"tpr","fpr")
performance(pred,"auc")@y.values
#the area under the curve: 0.8632756
plot(perf)
set.seed(2016)
ctrl <- trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(2016)
try <- train(Class ~ ., data = v_train, method = "rpart",
trControl = ctrl, tuneGrid=expand.grid(cp=seq(0.0001,0.1,0.0001)))
try$bestTune
#I got that best cp=0.0131
#Let me see the accuracy using cp=0.0131
fit2<-rpart(Class~., data=v_train, method="class", cp=0.0131)
pred_class2<-predict(fit2, v_test, type="class")
confusionMatrix(pred_class2, v_test$Class, positive="republican")
printcp(fit)
min.xerror <- fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"]
min.xerror
#Now with looking closer to the results of my experiment (Cross Validation)
try$results
# We can see that starting from cp=0.0001 until cp=0.0131
#The accuracy is the same(maximum), so taking any value of them will give
#the same results, and the initial cp=0.01 is included in that interval
#So everything is fine, I can submit my homework peacfully :)
prp(fit2, type=1, extra=4, faclen=0,tweak=1.0, main="Decision Tree for voting")
fancyRpartPlot(fit2, tweak=1.)
