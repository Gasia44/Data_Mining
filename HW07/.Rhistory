mean(least_Risky$address)
mean(least_Risky$employ)
#In average, they have been working in their current position for 14 years
#and in average they have the same address for 14 years
Most_Risky<-scoring[scoring$default=="Yes",]
Most_Risky <- arrange(Most_Risky,-Most_Risky$default_ProbYES )
Most_Risky <- Most_Risky[1:38,]
summary(Most_Risky)
summary(least_Risky)
Most_Risky <- Most_Risky[1:38,]
Most_Risky<-scoring[scoring$default=="Yes",]
View(scoring)
scoring<-read.csv("Scoring.csv")
model<-naiveBayes(default~., data=train, laplace=1)
pred1<-predict(model, newdata=scoring, type="raw")
pred<-predict(model, newdata=scoring)
pred1
scoring$default<-pred
scoring$default_ProbNO<-pred1[,1]
scoring$default_ProbYES<-pred1[,2]
View(scoring)
least_Risky<-scoring[scoring$default=="No",]
##Subset the highest 38 costumers. since we need 25% of all customers and we
#have in total 150 costumers so 150*25 /100 = 37.5 , i will take 38
#I found an interesting package that will sort my data, according to one variable
#It will sort in increasing order, and by putting '-' it will sort by decreasing order
#install.packages("plyr")
library(plyr)
least_Risky <- arrange(least_Risky,-default_ProbNO )
least_Risky <- least_Risky[1:38,]
summary(least_Risky)
hist(scoring$age)
hist(least_Risky$age)
plot(least_Risky$age, least_Risky$income)
hist(least_Risky$income)
mean(least_Risky$income)
#Mostly, their age is between 35 and 40
#Mostly, their average income is 60.60526$
#Those are the costumers that their education is didn't complete high school,
mean(least_Risky$address)
mean(least_Risky$employ)
#In average, they have been working in their current position for 16 years
#and in average they have the same address for 15 years
# Bonus point
#8. Compare top 25% of risky customers (Quartile 4) with bottom 25% of risky customers (Quartile 1).
# What are the main differences you see? Generate 1-2 tables and graphs for the analysis. (10 points)
###risky=Default=Yes
Most_Risky<-scoring[scoring$default=="Yes",]
Most_Risky <- arrange(Most_Risky,-Most_Risky$default_ProbYES )
Most_Risky <- Most_Risky[1:38,]
summary(Most_Risky)
summary(least_Risky)
scoring<-read.csv("Scoring.csv")
scoring$ed<-factor(scoring$ed, levels=c(1,2,3,4), labels=c("didn't complete high school","high school degree","college degree","undergraduate"))
model<-naiveBayes(default~., data=train, laplace=1)
pred1<-predict(model, newdata=scoring, type="raw")
pred<-predict(model, newdata=scoring)
pred1
scoring$default<-pred
scoring$default_ProbNO<-pred1[,1]
scoring$default_ProbYES<-pred1[,2]
#7. Identify the top 25% of customers that are least risky.
# Describe them with the variables you have in the scoring dataset.(7)
###Least risky= Default NO
least_Risky<-scoring[scoring$default=="No",]
##Subset the highest 38 costumers. since we need 25% of all customers and we
#have in total 150 costumers so 150*25 /100 = 37.5 , i will take 38
#I found an interesting package that will sort my data, according to one variable
#It will sort in increasing order, and by putting '-' it will sort by decreasing order
#install.packages("plyr")
library(plyr)
least_Risky <- arrange(least_Risky,-default_ProbNO )
least_Risky <- least_Risky[1:38,]
summary(least_Risky)
hist(scoring$age)
hist(least_Risky$age)
plot(least_Risky$age, least_Risky$income)
hist(least_Risky$income)
mean(least_Risky$income)
#Those are the costumers that their education is didn't complete high school,
#Mostly, their age is between 35 and 40
#Mostly, their average income is 60.60526$
mean(least_Risky$address)
mean(least_Risky$employ)
#In average, they have been working in their current position for 16 years
#and in average they have the same address for 15 years
# Bonus point
#8. Compare top 25% of risky customers (Quartile 4) with bottom 25% of risky customers (Quartile 1).
# What are the main differences you see? Generate 1-2 tables and graphs for the analysis. (10 points)
###risky=Default=Yes
Most_Risky<-scoring[scoring$default=="Yes",]
Most_Risky <- arrange(Most_Risky,-Most_Risky$default_ProbYES )
Most_Risky <- Most_Risky[1:38,]
summary(Most_Risky)
scoring<-read.csv(("Scoring.csv")
scoring$ed<-factor(scoring$ed)
model<-naiveBayes(default~., data=train, laplace=1)
scoring<-read.csv(("Scoring.csv")
scoring<-read.csv("Scoring.csv")
scoring<-read.csv("Scoring.csv")
scoring$ed<-factor(scoring$ed)
model<-naiveBayes(default~., data=train, laplace=1)
pred1<-predict(model, newdata=scoring, type="raw")
pred<-predict(model, newdata=scoring)
pred1
scoring$default<-pred
scoring$default_ProbNO<-pred1[,1]
scoring$default_ProbYES<-pred1[,2]
#7. Identify the top 25% of customers that are least risky.
# Describe them with the variables you have in the scoring dataset.(7)
###Least risky= Default NO
least_Risky<-scoring[scoring$default=="No",]
##Subset the highest 38 costumers. since we need 25% of all customers and we
#have in total 150 costumers so 150*25 /100 = 37.5 , i will take 38
#I found an interesting package that will sort my data, according to one variable
#It will sort in increasing order, and by putting '-' it will sort by decreasing order
#install.packages("plyr")
library(plyr)
least_Risky <- arrange(least_Risky,-default_ProbNO )
least_Risky <- least_Risky[1:38,]
summary(least_Risky)
hist(scoring$age)
hist(least_Risky$age)
plot(least_Risky$age, least_Risky$income)
hist(least_Risky$income)
mean(least_Risky$income)
#Those are the costumers that their education is didn't complete high school,
#Mostly, their age is between 35 and 40
#Mostly, their average income is 60.60526$
mean(least_Risky$address)
mean(least_Risky$employ)
#In average, they have been working in their current position for 16 years
#and in average they have the same address for 15 years
# Bonus point
#8. Compare top 25% of risky customers (Quartile 4) with bottom 25% of risky customers (Quartile 1).
# What are the main differences you see? Generate 1-2 tables and graphs for the analysis. (10 points)
###risky=Default=Yes
Most_Risky<-scoring[scoring$default=="Yes",]
Most_Risky <- arrange(Most_Risky,-Most_Risky$default_ProbYES )
Most_Risky <- Most_Risky[1:38,]
summary(Most_Risky)
View(scoring)
scoring<-read.csv("Scoring.csv")
model<-naiveBayes(default~., data=train, laplace=1)
pred1<-predict(model, newdata=scoring, type="raw")
pred<-predict(model, newdata=scoring)
pred1
scoring$default<-pred
scoring$default_ProbNO<-pred1[,1]
scoring$default_ProbYES<-pred1[,2]
#7. Identify the top 25% of customers that are least risky.
# Describe them with the variables you have in the scoring dataset.(7)
###Least risky= Default NO
least_Risky<-scoring[scoring$default=="No",]
##Subset the highest 38 costumers. since we need 25% of all customers and we
#have in total 150 costumers so 150*25 /100 = 37.5 , i will take 38
#I found an interesting package that will sort my data, according to one variable
#It will sort in increasing order, and by putting '-' it will sort by decreasing order
#install.packages("plyr")
library(plyr)
least_Risky <- arrange(least_Risky,-default_ProbNO )
least_Risky <- least_Risky[1:38,]
summary(least_Risky)
hist(scoring$age)
hist(least_Risky$age)
plot(least_Risky$age, least_Risky$income)
hist(least_Risky$income)
mean(least_Risky$income)
#Those are the costumers that their education is didn't complete high school,
#Mostly, their age is between 35 and 40
#Mostly, their average income is 60.60526$
mean(least_Risky$address)
mean(least_Risky$employ)
#In average, they have been working in their current position for 16 years
#and in average they have the same address for 15 years
# Bonus point
#8. Compare top 25% of risky customers (Quartile 4) with bottom 25% of risky customers (Quartile 1).
# What are the main differences you see? Generate 1-2 tables and graphs for the analysis. (10 points)
###risky=Default=Yes
Most_Risky<-scoring[scoring$default=="Yes",]
Most_Risky <- arrange(Most_Risky,-Most_Risky$default_ProbYES )
Most_Risky <- Most_Risky[1:38,]
summary(Most_Risky)
summary(least_Risky)
table(least_Risky$ed)
table(Most_Risky$ed)
par(mfrow=c(1,2))
barplot(table(least_Risky$ed), main="Least Risky costumers")
barplot(table(Most_Risky$ed), main="Most Risky costumers" )
##With looking to the barplot and table of Least Risky people, most of them didn't complete high school
#only one person completed high school degree
##Wherease looking to the barplot and table Most Risky people, most of them has a
#college degree and are undergraduate
#This means that the level of education plays a big role in defaulting
age_income_least_risky<-aggregate(least_Risky[,c("age", "income")], by=list(least_Risky$ed), FUN="mean", na.rm=T)
age_income_most_risky<-aggregate(Most_Risky[,c("age", "income")], by=list(Most_Risky$ed), FUN="mean", na.rm=T)
age_income_least_risky
age_income_most_risky
par(mfrow=c(1,2))
hist(least_Risky$income)
hist(Most_Risky$income)
mean(least_Risky$income)
mean(Most_Risky$income)
#The average income for most risky costumers is higher than the average income of least risky costumers
#This is interesting for me, as i tought people with low income will tends more to default,
#but the analysis says that the higher income costumers tends more to default the loan :D
#I can give some assumptions to this phenomena, costumers with high incomes, tend to get
#more expensive stuff with thinking that they can afford anything, BUT SURPRISE they
#can't :D
par(mfrow=c(1,2))
hist(least_Risky$creddebt)
hist(Most_Risky$creddebt)
mean(least_Risky$creddebt)
mean(Most_Risky$creddebt)
#The average of Least risky costumers credit card debt in thousands is 1 thousand dollar
#The average of Most risky costumers credit card debt in thousands is 3.5 thousand dollars
#The Most risky debt is almos 4 times the least risky debt, this somehow explains
#why list risky people doesn't tend to do default loan, as they can only spend one thousand
#dollar per month and they can afford it.
View(train)
scoring<-read.csv("Scoring.csv")
scoring<-read.csv("Scoring.csv")
scoring$ed<-factor(scoring$ed, levels=c(1,2,3,4,5), labels=c("didn't complete high school","high school degree","college degree","undergraduate", "postgraduate"))
model<-naiveBayes(default~., data=train, laplace=1)
pred1<-predict(model, newdata=scoring, type="raw")
pred<-predict(model, newdata=scoring)
pred1
scoring$default<-pred
scoring$default_ProbNO<-pred1[,1]
scoring$default_ProbYES<-pred1[,2]
table(scoring$default)
View(least_Risky)
View(scoring)
Most_Risky<-scoring[scoring$default=="No",]
Most_Risky <- arrange(Most_Risky,Most_Risky$default_ProbNo )
Most_Risky<-scoring[scoring$default=="No",]
Most_Risky <- arrange(Most_Risky,Most_Risky$default_ProbNo )
View(Most_Risky)
Most_Risky <- arrange(Most_Risky,Most_Risky$default_ProbNO )
View(Most_Risky)
Most_Risky <- arrange(scoring,scoring$default_ProbNO )
View(least_Risky)
View(Most_Risky)
Most_Risky <- Most_Risky[1:38,]
summary(Most_Risky)
summary(least_Risky)
table(least_Risky$ed)
table(Most_Risky$ed)
table(least_Risky$ed)
View(Most_Risky)
table(Most_Risky$ed)
View(least_Risky)
scoring<-read.csv("Scoring.csv")
scoring$ed<-factor(scoring$ed, levels=c(1,2,3,4,5), labels=c("didn't complete high school","high school degree","college degree","undergraduate", "postgraduate"))
model<-naiveBayes(default~., data=train, laplace=1)
pred1<-predict(model, newdata=scoring, type="raw")
pred<-predict(model, newdata=scoring)
pred1
scoring$default<-pred
scoring$default_ProbNO<-pred1[,1]
scoring$default_ProbYES<-pred1[,2]
table(scoring$default)
#7. Identify the top 25% of customers that are least risky.
# Describe them with the variables you have in the scoring dataset.(7)
###Least risky= Default NO
least_Risky<-scoring[scoring$default=="No",]
##Subset the highest 38 costumers. since we need 25% of all customers and we
#have in total 150 costumers so 150*25 /100 = 37.5 , i will take 38
#I found an interesting package that will sort my data, according to one variable
#It will sort in increasing order, and by putting '-' it will sort by decreasing order
#install.packages("plyr")
library(plyr)
least_Risky <- arrange(least_Risky,-default_ProbNO )
least_Risky <- least_Risky[1:38,]
summary(least_Risky)
hist(scoring$age)
hist(least_Risky$age)
plot(least_Risky$age, least_Risky$income)
hist(least_Risky$income)
mean(least_Risky$income)
#Those are the costumers that their education is didn't complete high school,
#Mostly, their age is between 35 and 40
#Mostly, their average income is 60.60526$
mean(least_Risky$address)
mean(least_Risky$employ)
Most_Risky <- arrange(scoring,scoring$default_ProbNO )
Most_Risky <- Most_Risky[1:38,]
summary(Most_Risky)
summary(least_Risky)
table(least_Risky$ed)
table(Most_Risky$ed)
scoring<-read.csv("Scoring.csv")
scoring$ed<-factor(scoring$ed, levels=c(1,2,3,4,5), labels=c("didn't complete high school","high school degree","college degree","undergraduate", "postgraduate"))
model<-naiveBayes(default~., data=train, laplace=1)
pred1<-predict(model, newdata=scoring, type="raw")
pred<-predict(model, newdata=scoring)
pred1
scoring$default<-pred
scoring$default_ProbNO<-pred1[,1]
pred1
scoring$default<-pred
scoring$default_ProbNO<-pred1[,1]
scoring$default_ProbYES<-pred1[,2]
table(scoring$default)
#7. Identify the top 25% of customers that are least risky.
#7. Identify the top 25% of customers that are least risky.
# Describe them with the variables you have in the scoring dataset.(7)
###Least risky= Default NO
least_Risky<-scoring[scoring$default=="No",]
##Subset the highest 38 costumers. since we need 25% of all customers and we
#have in total 150 costumers so 150*25 /100 = 37.5 , i will take 38
#I found an interesting package that will sort my data, according to one variable
#It will sort in increasing order, and by putting '-' it will sort by decreasing order
#install.packages("plyr")
library(plyr)
least_Risky <- arrange(least_Risky,-default_ProbNO )
least_Risky <- least_Risky[1:38,]
summary(least_Risky)
hist(scoring$age)
hist(least_Risky$age)
plot(least_Risky$age, least_Risky$income)
hist(least_Risky$income)
mean(least_Risky$income)
hist(least_Risky$ed)
barplot(table(least_Risky$ed), main="Least Risky costumers")
table(least_Risky$ed)
hist(least_Risky$income)
mean(least_Risky$income)
summary(least_Risky)
hist(scoring$age)
hist(least_Risky$age)
mean(least_Risky$age)
Most_Risky <- arrange(scoring,scoring$default_ProbNO )
Most_Risky <- Most_Risky[1:38,]
summary(Most_Risky)
summary(least_Risky)
table(least_Risky$ed)
table(Most_Risky$ed)
par(mfrow=c(1,2))
barplot(table(least_Risky$ed), main="Least Risky costumers")
barplot(table(Most_Risky$ed), main="Most Risky costumers" )
age_income_least_risky<-aggregate(least_Risky[,c("age", "income")], by=list(least_Risky$ed), FUN="mean", na.rm=T)
age_income_most_risky<-aggregate(Most_Risky[,c("age", "income")], by=list(Most_Risky$ed), FUN="mean", na.rm=T)
age_income_least_risky
age_income_most_risky
par(mfrow=c(1,2))
hist(least_Risky$income)
hist(Most_Risky$income)
mean(least_Risky$income)
mean(Most_Risky$income)
par(mfrow=c(1,2))
hist(least_Risky$creddebt)
hist(Most_Risky$creddebt)
mean(least_Risky$creddebt)
mean(Most_Risky$creddebt)
credit<-read.csv("Credit.csv")
credit$default<-factor(credit$default, levels=c(0,1), labels=c("No", "Yes"))
credit$ed<-factor(credit$ed, levels=c(1,2,3,4,5), labels=c("didn't complete high school","high school degree","college degree","undergraduate", "postgraduate"))
library(lattice)
library(ggplot2)
library(caret)
set.seed(2016)
trainIndex<-createDataPartition(credit$default, p=.8, list=F)
train<-credit[trainIndex,]
test<-credit[-trainIndex,]
#Check the proportions
prop.table(table(credit$default) )
prop.table(table(train$default) )
prop.table(table(test$default) )
#2. Create a naive bayes model on the dataset. Set
# Laplace equal to 1. What is the accuracy of the model? (7)
library(e1071)
model<-naiveBayes(default~., data=train, laplace=1)
#model$tables
#model$apriori
pred<-predict(model, newdata=test)
confusionMatrix(pred, test$default)
# Accuracy : 0.741
#Sensitivity : 0.9029
#Specificity : 0.2778
#3. Plot the ROC curve, make sure you have the colors of the
# thresholds on the curve. Give explanation to the coloring of
# the curve: what does it show?? What is the AUC? (7)
library(ROCR)
pred1<-predict(model, newdata=test, type="raw")
pred_test<-prediction(pred1[,2], test$default,label.ordering =c("No", "Yes"))
perf<-performance(pred_test,"tpr","fpr")
plot(perf, colorize=T)
##The color at each point on the ROC curve represents a sensitivity/specificity pair corresponding
#to a particular decision threshold
#The closer the ROC curve is to the upper left corner, the higher will be the overall
#accuracy
#What we are interested in, is to make the true positive rate as high as possibly
#and decrease false positive rate
#This can happen when treshold is almos 0.2
performance(pred_test, "auc")@y.values
#AUC:0.7208738
#4. Given that someone defaulted, what is the probability that
# he/she has postgarduate degree? (7)
model<-naiveBayes(default~ed, data=train, laplace=1)
model$tables
#Given that someone defaulted,the probability that he/she has postgarduate
#degree is 0.01315789
#5.Take any of the classification methods that we studied so
# far and build a model using it. Compare that model with the
# Naive Bayes model. Which one does better? Comment. (7)
library(rpart)
fit<-rpart(default~., data=train, method="class")
library(rpart.plot)
library(rattle)
prp(fit, type=1, extra=4, faclen=0,tweak=1.5, main="Decision Tree for voting")
pred_class<-predict(fit, test,type="class")
table( Prediction=pred_class,Actual=test$default)
confusionMatrix(pred_class,test$default, positive="Yes")
prp(fit, type=1, extra=4, faclen=0,tweak=1.2, main="Decision Tree for voting")
pred_class<-predict(fit, test,type="class")
table( Prediction=pred_class,Actual=test$default)
confusionMatrix(pred_class,test$default, positive="Yes")
scoring<-read.csv("Scoring.csv")
scoring$ed<-factor(scoring$ed, levels=c(1,2,3,4,5), labels=c("didn't complete high school","high school degree","college degree","undergraduate", "postgraduate"))
model<-naiveBayes(default~., data=train, laplace=1)
pred1<-predict(model, newdata=scoring, type="raw")
pred<-predict(model, newdata=scoring)
pred1
scoring$default<-pred
scoring$default_ProbNO<-pred1[,1]
scoring$default_ProbYES<-pred1[,2]
table(scoring$default)
#7. Identify the top 25% of customers that are least risky.
# Describe them with the variables you have in the scoring dataset.(7)
###Least risky= Default NO
least_Risky<-scoring[scoring$default=="No",]
##Subset the highest 38 costumers. since we need 25% of all customers and we
#have in total 150 costumers so 150*25 /100 = 37.5 , i will take 38
#I found an interesting package that will sort my data, according to one variable
#It will sort in increasing order, and by putting '-' it will sort by decreasing order
#install.packages("plyr")
library(plyr)
least_Risky <- arrange(least_Risky,-default_ProbNO )
least_Risky <- least_Risky[1:38,]
summary(least_Risky)
hist(scoring$age)
hist(least_Risky$age)
mean(least_Risky$age)
plot(least_Risky$age, least_Risky$income)
hist(least_Risky$income)
mean(least_Risky$income)
barplot(table(least_Risky$ed), main="Least Risky costumers")
table(least_Risky$ed)
#Those are the costumers that 70% of them, their education is didn't complete high school,
#and then 23% have high school degree
#Mostly, their age is between 35 and 40
#Mostly, their average income is 60.60526$
mean(least_Risky$address)
mean(least_Risky$employ)
#In average, they have been working in their current position for 16 years
#and in average they have the same address for 15 years
# Bonus point
#8. Compare top 25% of risky customers (Quartile 4) with bottom 25% of risky customers (Quartile 1).
# What are the main differences you see? Generate 1-2 tables and graphs for the analysis. (10 points)
###risky=Default=Yes
#Most_Risky<-scoring[scoring$default=="No",]
Most_Risky <- arrange(scoring,scoring$default_ProbNO )
Most_Risky <- Most_Risky[1:38,]
summary(Most_Risky)
summary(least_Risky)
table(least_Risky$ed)
table(Most_Risky$ed)
par(mfrow=c(1,2))
barplot(table(least_Risky$ed), main="Least Risky costumers")
barplot(table(Most_Risky$ed), main="Most Risky costumers" )
##With looking to the barplot and table of Least Risky people, most of them 70% didn't complete high school
#and small amount 23% have high school degree
##Wherease looking to the barplot and table Most Risky people, 39% didn't complete high school
#and 31% have  high school degree , and 15% have college degree, and 13% have undergraduate degree
#This means that the level of education plays a  role in defaulting
age_income_least_risky<-aggregate(least_Risky[,c("age", "income")], by=list(least_Risky$ed), FUN="mean", na.rm=T)
age_income_most_risky<-aggregate(Most_Risky[,c("age", "income")], by=list(Most_Risky$ed), FUN="mean", na.rm=T)
age_income_least_risky
age_income_most_risky
par(mfrow=c(1,2))
hist(least_Risky$income)
hist(Most_Risky$income)
mean(least_Risky$income)
mean(Most_Risky$income)
#The average income for most risky costumers is higher than the average income of least risky costumers
#This is interesting for me, as i tought people with low income will tends more to default,
#but the analysis says that the higher income costumers tends more to default the loan :D
#I can give some assumptions to this phenomena, costumers with high incomes, tend to get
#more expensive stuff with thinking that they can afford anything, BUT SURPRISE they
#can't :D
par(mfrow=c(1,2))
hist(least_Risky$creddebt)
hist(Most_Risky$creddebt)
mean(least_Risky$creddebt)
mean(Most_Risky$creddebt)
#The average of Least risky costumers credit card debt in thousands is 1 thousand dollar
#The average of Most risky costumers credit card debt in thousands is 3.9 thousand dollars
#The Most risky costumers debt is almost 4 times the least risky costumers debt, this somehow explains
#why list risky people doesn't tend to do default loan, as they can only spend one thousand
#dollar per month and they can afford that.
hist(least_Risky$creddebt)
mean(least_Risky$creddebt)
mean(least_Risky$employ)
mean(Most_Risky$employ)
hist(least_Risky$employ)
par(mfrow=c(1,2))
hist(least_Risky$employ)
hist(Most_Risky$employ)
mean(least_Risky$employ)
mean(Most_Risky$employ)
View(least_Risky)
